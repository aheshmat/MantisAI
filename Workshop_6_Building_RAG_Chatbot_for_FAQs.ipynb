{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aheshmat/MantisAI/blob/main/Workshop_6_Building_RAG_Chatbot_for_FAQs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uO9g-nku2ko"
      },
      "source": [
        "# Workshop 6: Building a RAG Chatbot for FAQ Responses\n",
        "### InterSystems AI for Software Developers\n",
        "\n",
        "In this workshop, we will build a Retrieval-Augmented Generation (RAG) system for responding to e-commerce FAQs.\n",
        "The goal is to create a simple chatbot that can retrieve relevant FAQ responses based on user queries.\n",
        "By the end of this session, we hope you will have a chatbot deployed on Hugging Face Spaces.\n",
        "\n",
        "We'll load a [dataset of e-commerce FAQs](https://huggingface.co/datasets/NebulaByte/E-Commerce_FAQs) using the Hugging Face `datasets` library.\n",
        "\n",
        "Here’s a quick breakdown of relevant fields:\n",
        "* `question`: Contains the FAQ question text, ideal as input for retrieval.\n",
        "* `answer`: Contains the answer to each FAQ, which we can use as the target output in our response generation.\n",
        "* `category`: Could be useful for context if we want to segment responses by topic or apply specific embeddings for different categories.\n",
        "* `que_ans`: Combination of question and answer, which may serve as a good retrieval field, especially if we want to capture both question structure and response context.\n",
        "\n",
        "### Suggested Pipeline Adaptation\n",
        "1. **Document Store**: Store each `que_ans` field as a document in the vector database. This allows the RAG pipeline to retrieve the most contextually relevant question-answer pairs.\n",
        "2. **Retrieval**: Use `question` as input for retrieving similar FAQs, which will help refine the search to show the best match.\n",
        "3. **Generation**: Generate responses or refine the retrieved answers based on context from the query."
      ],
      "id": "0uO9g-nku2ko"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "aYy12ly7wTjo"
      },
      "id": "aYy12ly7wTjo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKhMDFt3u2kq"
      },
      "source": [
        "## Part 1: Data Preparation\n",
        "\n",
        "### Steps:\n",
        "- Load the FAQ dataset.\n",
        "- Preprocess it for use in a RAG system.\n",
        "\n",
        "### Expected Output:\n",
        "- `documents`: A list of `Document` objects containing FAQs.\n"
      ],
      "id": "iKhMDFt3u2kq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbMy4hapu2kq"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the FAQ dataset\n",
        "\n",
        "ds = load_dataset(\"NebulaByte/E-Commerce_FAQs\")\n",
        "\n",
        "# Preprocess if necessary\n"
      ],
      "id": "hbMy4hapu2kq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKdBfagTu2kr"
      },
      "source": [
        "### Preparing Data for RAG\n",
        "Here we’ll structure the data for use in RAG, creating a list of `Document` objects. Each document combines `question` and `answer` for better retrieval context.\n"
      ],
      "id": "jKdBfagTu2kr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnkcV65Ju2ks"
      },
      "outputs": [],
      "source": [
        "# Convert each FAQ to a Document object for RAG\n",
        "documents = []\n",
        "\n",
        "\n",
        "print(f\"Total documents prepared: {len(documents)}\")"
      ],
      "id": "PnkcV65Ju2ks"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfX3eL9lu2ks"
      },
      "source": [
        "## Part 2: Document Store and Embedding Setup\n",
        "We will store our FAQ documents in a vector database and set up embeddings for efficient retrieval.\n",
        "\n",
        "### Steps:\n",
        "- Initialize a Chroma document store.\n",
        "- Populate the store with embedded FAQ documents."
      ],
      "id": "UfX3eL9lu2ks"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP9Unb8Zu2ks"
      },
      "outputs": [],
      "source": [
        "from haystack_integrations.document_stores.chroma import ChromaDocumentStore\n",
        "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
        "\n",
        "# Initialize document store\n",
        "\n",
        "\n",
        "# Add documents to the document store\n",
        "\n",
        "print(f\"Total documents in the store: {len()}\")"
      ],
      "id": "kP9Unb8Zu2ks"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im50bTA7u2ks"
      },
      "source": [
        "### Embedding the Documents\n",
        "We’ll now create an embedding pipeline to add vector embeddings for each document in the store.\n"
      ],
      "id": "Im50bTA7u2ks"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72ygRMbEu2ks"
      },
      "outputs": [],
      "source": [
        "# Initialize the embedding model\n",
        "embedder = SentenceTransformersDocumentEmbedder(model_name_or_path='all-MiniLM-L6-v2')\n",
        "\n",
        "# Embed documents in the document store\n",
        "document_store.update_embeddings(embedder)"
      ],
      "id": "72ygRMbEu2ks"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moKXR7YFu2kt"
      },
      "source": [
        "## Part 3: Build a Basic RAG Pipeline\n",
        "We will create a RAG pipeline that combines retrieval and generation to answer user queries.\n",
        "\n",
        "### Steps:\n",
        "- Set up retrieval using the Chroma document store.\n",
        "- Create a generator component to rephrase retrieved answers.\n",
        "- Assemble a RAG pipeline that uses retrieval for context.\n"
      ],
      "id": "moKXR7YFu2kt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUSNwp9su2kt"
      },
      "outputs": [],
      "source": [
        "from haystack import Pipeline\n",
        "from haystack.components.generators import HuggingFaceLocalGenerator\n",
        "from haystack_integrations.components.retrievers.chroma import ChromaEmbeddingRetriever\n",
        "\n",
        "# Initialize retriever and generator\n",
        "\n",
        "\n",
        "# Build RAG pipeline\n"
      ],
      "id": "HUSNwp9su2kt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6wM9MKju2kt"
      },
      "source": [
        "### Testing the RAG Pipeline\n",
        "Now, let’s test the RAG pipeline by asking it a question from the FAQ dataset.\n"
      ],
      "id": "c6wM9MKju2kt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suuduT3Au2kt"
      },
      "outputs": [],
      "source": [
        "# Sample query\n",
        "query = \"What is the return policy?\"\n",
        "prediction = \"\"\n",
        "print(\"Response:\", prediction['answers'][0].answer)"
      ],
      "id": "suuduT3Au2kt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jseBZ4Ldu2kt"
      },
      "source": [
        "## Part 4: Deploying as a Chatbot on Hugging Face Spaces\n",
        "Finally, we’ll deploy this RAG model as an interactive chatbot on Hugging Face Spaces. This allows you to test it with real questions.\n",
        "\n",
        "### Steps:\n",
        "- Define a Gradio interface for the chatbot (search for `gradio chatbot` to find the documentation).\n",
        "- Deploy it to Hugging Face Spaces."
      ],
      "id": "jseBZ4Ldu2kt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jdrv9hPu2kt"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Define chatbot function\n",
        "\n",
        "\n",
        "# Create Gradio interface\n",
        "\n",
        "\n",
        "# Launch interface\n"
      ],
      "id": "3jdrv9hPu2kt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U34Om139u2ku"
      },
      "source": [
        "## Potential questions to test\n",
        "\n",
        "**Shipping and Delivery**:\n",
        "* \"Hey! How long will my order take to get here?\"\n",
        "* \"Do you guys do next-day delivery?\"\n",
        "* \"Can I get updates on where my package is right now?\"\n",
        "\n",
        "⠀**Returns and Refunds**:\n",
        "* \"Hi, what's the deal with returns if I don’t like something?\"\n",
        "* \"How do I go about getting a refund?\"\n",
        "* \"Is there a fee if I want to send something back?\"\n",
        "\n",
        "⠀**Account and Orders**:\n",
        "* \"Hey, I forgot my password. Can you help me reset it?\"\n",
        "* \"I just placed an order—any chance I can cancel it?\"\n",
        "* \"How do I check what I’ve ordered in the past?\"\n",
        "\n",
        "⠀**Product Information**:\n",
        "* \"Are your products eco-friendly by any chance?\"\n",
        "* \"Do I get a discount if I buy a bunch at once?\"\n",
        "* \"Got any tips on choosing the right size?\"\n",
        "\n",
        "⠀**Payment and Security**:\n",
        "* \"What types of payment do you guys take?\"\n",
        "* \"Is my info safe when I pay here?\"\n",
        "* \"Do you offer payment plans, like monthly installments?\"\n",
        "\n",
        "⠀**General Inquiries**:\n",
        "* \"How can I get in touch with someone from your team?\"\n",
        "* \"Do you have gift wrapping options?\"\n",
        "* \"What should I do if something arrives damaged?\"\n",
        "\n",
        "\n",
        "## Conclusion and Next Steps\n",
        "You’ve successfully created and deployed a chatbot that answers e-commerce FAQs using RAG.\n",
        "\n",
        "Consider these additional steps:\n",
        "- Improve retrieval accuracy with additional data.\n",
        "- Experiment with different embedding models.\n",
        "- Add advanced features, like re-ranking retrieved answers."
      ],
      "id": "U34Om139u2ku"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}